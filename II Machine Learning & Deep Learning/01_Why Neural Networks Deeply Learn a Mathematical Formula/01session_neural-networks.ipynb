{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#01 | Why Neural Networks Deeply Learn a Mathematical Formula</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Subscribe to my [Blog ‚Üó](https://blog.pythonassembly.com/)\n",
    "- Let's keep in touch on [LinkedIn ‚Üó](www.linkedin.com/in/jsulopz) üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discipline to Search Solutions in Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Apply the following steps when **looking for solutions in Google**:\n",
    ">\n",
    "> 1. **Necesity**: How to load an Excel in Python?\n",
    "> 2. **Search in Google**: by keywords\n",
    ">   - `load excel python`\n",
    ">   - ~~how to load excel in python~~\n",
    "> 3. **Solution**: What's the `function()` that loads an Excel in Python?\n",
    ">   - A Function to Programming is what the Atom to Phisics.\n",
    ">   - Every time you want to do something in programming\n",
    ">   - **You will need a `function()`** to make it\n",
    ">   - Theferore, you must **detect parenthesis `()`**\n",
    ">   - Out of all the words that you see in a website\n",
    ">   - Because they indicate the presence of a `function()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Machine Learns...\n",
    ">\n",
    "> But, **what does it learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the Machine Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practical Example ‚Üí [Tesla Autopilot](https://www.tesla.com/AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example where It Fails ‚Üí [Tesla Confuses Moon with Semaphore](https://twitter.com/Carnage4Life/status/1418920100086784000?s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Simply execute the following lines of code to load the data.\n",
    "> - This dataset contains **statistics about Car Accidents** (columns)\n",
    "> - In each one of **USA States** (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>23.9</td>\n",
       "      <td>5.497</td>\n",
       "      <td>10.038</td>\n",
       "      <td>23.661</td>\n",
       "      <td>20.554</td>\n",
       "      <td>688.75</td>\n",
       "      <td>109.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.200</td>\n",
       "      <td>3.360</td>\n",
       "      <td>10.920</td>\n",
       "      <td>10.680</td>\n",
       "      <td>878.41</td>\n",
       "      <td>165.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>19.5</td>\n",
       "      <td>4.095</td>\n",
       "      <td>5.655</td>\n",
       "      <td>15.990</td>\n",
       "      <td>15.795</td>\n",
       "      <td>767.91</td>\n",
       "      <td>155.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.640</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.040</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>13.6</td>\n",
       "      <td>5.032</td>\n",
       "      <td>3.808</td>\n",
       "      <td>10.744</td>\n",
       "      <td>12.920</td>\n",
       "      <td>835.50</td>\n",
       "      <td>139.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "ND       23.9     5.497   10.038          23.661       20.554       688.75   \n",
       "CA       12.0     4.200    3.360          10.920       10.680       878.41   \n",
       "TN       19.5     4.095    5.655          15.990       15.795       767.91   \n",
       "AL       18.8     7.332    5.640          18.048       15.040       784.55   \n",
       "CO       13.6     5.032    3.808          10.744       12.920       835.50   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "ND          109.72  \n",
       "CA          165.63  \n",
       "TN          155.57  \n",
       "AL          145.08  \n",
       "CO          139.91  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `fit()` a Neural Network Model in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Find the `function()` in **Google**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_17066/1110569478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_17066/1135494217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 20:43:42.875083: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-08 20:43:42.875277: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_17066/1135494217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), slice(1, -1, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_17066/3787799436.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3359\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), slice(1, -1, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "df[:, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.640</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.040</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>7.421</td>\n",
       "      <td>4.525</td>\n",
       "      <td>16.290</td>\n",
       "      <td>17.014</td>\n",
       "      <td>1053.48</td>\n",
       "      <td>133.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>6.510</td>\n",
       "      <td>5.208</td>\n",
       "      <td>15.624</td>\n",
       "      <td>17.856</td>\n",
       "      <td>899.47</td>\n",
       "      <td>110.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>4.032</td>\n",
       "      <td>5.824</td>\n",
       "      <td>21.056</td>\n",
       "      <td>21.280</td>\n",
       "      <td>827.34</td>\n",
       "      <td>142.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.200</td>\n",
       "      <td>3.360</td>\n",
       "      <td>10.920</td>\n",
       "      <td>10.680</td>\n",
       "      <td>878.41</td>\n",
       "      <td>165.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>13.6</td>\n",
       "      <td>5.032</td>\n",
       "      <td>3.808</td>\n",
       "      <td>10.744</td>\n",
       "      <td>12.920</td>\n",
       "      <td>835.50</td>\n",
       "      <td>139.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>10.8</td>\n",
       "      <td>4.968</td>\n",
       "      <td>3.888</td>\n",
       "      <td>9.396</td>\n",
       "      <td>8.856</td>\n",
       "      <td>1068.73</td>\n",
       "      <td>167.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>16.2</td>\n",
       "      <td>6.156</td>\n",
       "      <td>4.860</td>\n",
       "      <td>14.094</td>\n",
       "      <td>16.038</td>\n",
       "      <td>1137.87</td>\n",
       "      <td>151.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>5.9</td>\n",
       "      <td>2.006</td>\n",
       "      <td>1.593</td>\n",
       "      <td>5.900</td>\n",
       "      <td>5.900</td>\n",
       "      <td>1273.89</td>\n",
       "      <td>136.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>17.9</td>\n",
       "      <td>3.759</td>\n",
       "      <td>5.191</td>\n",
       "      <td>16.468</td>\n",
       "      <td>16.826</td>\n",
       "      <td>1160.13</td>\n",
       "      <td>144.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>15.6</td>\n",
       "      <td>2.964</td>\n",
       "      <td>3.900</td>\n",
       "      <td>14.820</td>\n",
       "      <td>14.508</td>\n",
       "      <td>913.15</td>\n",
       "      <td>142.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI</th>\n",
       "      <td>17.5</td>\n",
       "      <td>9.450</td>\n",
       "      <td>7.175</td>\n",
       "      <td>14.350</td>\n",
       "      <td>15.225</td>\n",
       "      <td>861.18</td>\n",
       "      <td>120.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>15.3</td>\n",
       "      <td>5.508</td>\n",
       "      <td>4.437</td>\n",
       "      <td>13.005</td>\n",
       "      <td>14.994</td>\n",
       "      <td>641.96</td>\n",
       "      <td>82.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>12.8</td>\n",
       "      <td>4.608</td>\n",
       "      <td>4.352</td>\n",
       "      <td>12.032</td>\n",
       "      <td>12.288</td>\n",
       "      <td>803.11</td>\n",
       "      <td>139.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>14.5</td>\n",
       "      <td>3.625</td>\n",
       "      <td>4.205</td>\n",
       "      <td>13.775</td>\n",
       "      <td>13.775</td>\n",
       "      <td>710.46</td>\n",
       "      <td>108.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IA</th>\n",
       "      <td>15.7</td>\n",
       "      <td>2.669</td>\n",
       "      <td>3.925</td>\n",
       "      <td>15.229</td>\n",
       "      <td>13.659</td>\n",
       "      <td>649.06</td>\n",
       "      <td>114.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KS</th>\n",
       "      <td>17.8</td>\n",
       "      <td>4.806</td>\n",
       "      <td>4.272</td>\n",
       "      <td>13.706</td>\n",
       "      <td>15.130</td>\n",
       "      <td>780.45</td>\n",
       "      <td>133.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KY</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4.066</td>\n",
       "      <td>4.922</td>\n",
       "      <td>16.692</td>\n",
       "      <td>16.264</td>\n",
       "      <td>872.51</td>\n",
       "      <td>137.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>20.5</td>\n",
       "      <td>7.175</td>\n",
       "      <td>6.765</td>\n",
       "      <td>14.965</td>\n",
       "      <td>20.090</td>\n",
       "      <td>1281.55</td>\n",
       "      <td>194.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME</th>\n",
       "      <td>15.1</td>\n",
       "      <td>5.738</td>\n",
       "      <td>4.530</td>\n",
       "      <td>13.137</td>\n",
       "      <td>12.684</td>\n",
       "      <td>661.88</td>\n",
       "      <td>96.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>12.5</td>\n",
       "      <td>4.250</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.875</td>\n",
       "      <td>12.375</td>\n",
       "      <td>1048.78</td>\n",
       "      <td>192.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>8.2</td>\n",
       "      <td>1.886</td>\n",
       "      <td>2.870</td>\n",
       "      <td>7.134</td>\n",
       "      <td>6.560</td>\n",
       "      <td>1011.14</td>\n",
       "      <td>135.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>14.1</td>\n",
       "      <td>3.384</td>\n",
       "      <td>3.948</td>\n",
       "      <td>13.395</td>\n",
       "      <td>10.857</td>\n",
       "      <td>1110.61</td>\n",
       "      <td>152.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>9.6</td>\n",
       "      <td>2.208</td>\n",
       "      <td>2.784</td>\n",
       "      <td>8.448</td>\n",
       "      <td>8.448</td>\n",
       "      <td>777.18</td>\n",
       "      <td>133.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MS</th>\n",
       "      <td>17.6</td>\n",
       "      <td>2.640</td>\n",
       "      <td>5.456</td>\n",
       "      <td>1.760</td>\n",
       "      <td>17.600</td>\n",
       "      <td>896.07</td>\n",
       "      <td>155.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO</th>\n",
       "      <td>16.1</td>\n",
       "      <td>6.923</td>\n",
       "      <td>5.474</td>\n",
       "      <td>14.812</td>\n",
       "      <td>13.524</td>\n",
       "      <td>790.32</td>\n",
       "      <td>144.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT</th>\n",
       "      <td>21.4</td>\n",
       "      <td>8.346</td>\n",
       "      <td>9.416</td>\n",
       "      <td>17.976</td>\n",
       "      <td>18.190</td>\n",
       "      <td>816.21</td>\n",
       "      <td>85.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>14.9</td>\n",
       "      <td>1.937</td>\n",
       "      <td>5.215</td>\n",
       "      <td>13.857</td>\n",
       "      <td>13.410</td>\n",
       "      <td>732.28</td>\n",
       "      <td>114.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NV</th>\n",
       "      <td>14.7</td>\n",
       "      <td>5.439</td>\n",
       "      <td>4.704</td>\n",
       "      <td>13.965</td>\n",
       "      <td>14.553</td>\n",
       "      <td>1029.87</td>\n",
       "      <td>138.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>11.6</td>\n",
       "      <td>4.060</td>\n",
       "      <td>3.480</td>\n",
       "      <td>10.092</td>\n",
       "      <td>9.628</td>\n",
       "      <td>746.54</td>\n",
       "      <td>120.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NJ</th>\n",
       "      <td>11.2</td>\n",
       "      <td>1.792</td>\n",
       "      <td>3.136</td>\n",
       "      <td>9.632</td>\n",
       "      <td>8.736</td>\n",
       "      <td>1301.52</td>\n",
       "      <td>159.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NM</th>\n",
       "      <td>18.4</td>\n",
       "      <td>3.496</td>\n",
       "      <td>4.968</td>\n",
       "      <td>12.328</td>\n",
       "      <td>18.032</td>\n",
       "      <td>869.85</td>\n",
       "      <td>120.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NY</th>\n",
       "      <td>12.3</td>\n",
       "      <td>3.936</td>\n",
       "      <td>3.567</td>\n",
       "      <td>10.824</td>\n",
       "      <td>9.840</td>\n",
       "      <td>1234.31</td>\n",
       "      <td>150.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>16.8</td>\n",
       "      <td>6.552</td>\n",
       "      <td>5.208</td>\n",
       "      <td>15.792</td>\n",
       "      <td>13.608</td>\n",
       "      <td>708.24</td>\n",
       "      <td>127.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>23.9</td>\n",
       "      <td>5.497</td>\n",
       "      <td>10.038</td>\n",
       "      <td>23.661</td>\n",
       "      <td>20.554</td>\n",
       "      <td>688.75</td>\n",
       "      <td>109.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>14.1</td>\n",
       "      <td>3.948</td>\n",
       "      <td>4.794</td>\n",
       "      <td>13.959</td>\n",
       "      <td>11.562</td>\n",
       "      <td>697.73</td>\n",
       "      <td>133.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OK</th>\n",
       "      <td>19.9</td>\n",
       "      <td>6.368</td>\n",
       "      <td>5.771</td>\n",
       "      <td>18.308</td>\n",
       "      <td>18.706</td>\n",
       "      <td>881.51</td>\n",
       "      <td>178.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR</th>\n",
       "      <td>12.8</td>\n",
       "      <td>4.224</td>\n",
       "      <td>3.328</td>\n",
       "      <td>8.576</td>\n",
       "      <td>11.520</td>\n",
       "      <td>804.71</td>\n",
       "      <td>104.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>18.2</td>\n",
       "      <td>9.100</td>\n",
       "      <td>5.642</td>\n",
       "      <td>17.472</td>\n",
       "      <td>16.016</td>\n",
       "      <td>905.99</td>\n",
       "      <td>153.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RI</th>\n",
       "      <td>11.1</td>\n",
       "      <td>3.774</td>\n",
       "      <td>4.218</td>\n",
       "      <td>10.212</td>\n",
       "      <td>8.769</td>\n",
       "      <td>1148.99</td>\n",
       "      <td>148.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>23.9</td>\n",
       "      <td>9.082</td>\n",
       "      <td>9.799</td>\n",
       "      <td>22.944</td>\n",
       "      <td>19.359</td>\n",
       "      <td>858.97</td>\n",
       "      <td>116.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>19.4</td>\n",
       "      <td>6.014</td>\n",
       "      <td>6.402</td>\n",
       "      <td>19.012</td>\n",
       "      <td>16.684</td>\n",
       "      <td>669.31</td>\n",
       "      <td>96.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>19.5</td>\n",
       "      <td>4.095</td>\n",
       "      <td>5.655</td>\n",
       "      <td>15.990</td>\n",
       "      <td>15.795</td>\n",
       "      <td>767.91</td>\n",
       "      <td>155.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TX</th>\n",
       "      <td>19.4</td>\n",
       "      <td>7.760</td>\n",
       "      <td>7.372</td>\n",
       "      <td>17.654</td>\n",
       "      <td>16.878</td>\n",
       "      <td>1004.75</td>\n",
       "      <td>156.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UT</th>\n",
       "      <td>11.3</td>\n",
       "      <td>4.859</td>\n",
       "      <td>1.808</td>\n",
       "      <td>9.944</td>\n",
       "      <td>10.848</td>\n",
       "      <td>809.38</td>\n",
       "      <td>109.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>13.6</td>\n",
       "      <td>4.080</td>\n",
       "      <td>4.080</td>\n",
       "      <td>13.056</td>\n",
       "      <td>12.920</td>\n",
       "      <td>716.20</td>\n",
       "      <td>109.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>12.7</td>\n",
       "      <td>2.413</td>\n",
       "      <td>3.429</td>\n",
       "      <td>11.049</td>\n",
       "      <td>11.176</td>\n",
       "      <td>768.95</td>\n",
       "      <td>153.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WA</th>\n",
       "      <td>10.6</td>\n",
       "      <td>4.452</td>\n",
       "      <td>3.498</td>\n",
       "      <td>8.692</td>\n",
       "      <td>9.116</td>\n",
       "      <td>890.03</td>\n",
       "      <td>111.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>23.8</td>\n",
       "      <td>8.092</td>\n",
       "      <td>6.664</td>\n",
       "      <td>23.086</td>\n",
       "      <td>20.706</td>\n",
       "      <td>992.61</td>\n",
       "      <td>152.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WI</th>\n",
       "      <td>13.8</td>\n",
       "      <td>4.968</td>\n",
       "      <td>4.554</td>\n",
       "      <td>5.382</td>\n",
       "      <td>11.592</td>\n",
       "      <td>670.31</td>\n",
       "      <td>106.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>17.4</td>\n",
       "      <td>7.308</td>\n",
       "      <td>5.568</td>\n",
       "      <td>14.094</td>\n",
       "      <td>15.660</td>\n",
       "      <td>791.14</td>\n",
       "      <td>122.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "AL       18.8     7.332    5.640          18.048       15.040       784.55   \n",
       "AK       18.1     7.421    4.525          16.290       17.014      1053.48   \n",
       "AZ       18.6     6.510    5.208          15.624       17.856       899.47   \n",
       "AR       22.4     4.032    5.824          21.056       21.280       827.34   \n",
       "CA       12.0     4.200    3.360          10.920       10.680       878.41   \n",
       "CO       13.6     5.032    3.808          10.744       12.920       835.50   \n",
       "CT       10.8     4.968    3.888           9.396        8.856      1068.73   \n",
       "DE       16.2     6.156    4.860          14.094       16.038      1137.87   \n",
       "DC        5.9     2.006    1.593           5.900        5.900      1273.89   \n",
       "FL       17.9     3.759    5.191          16.468       16.826      1160.13   \n",
       "GA       15.6     2.964    3.900          14.820       14.508       913.15   \n",
       "HI       17.5     9.450    7.175          14.350       15.225       861.18   \n",
       "ID       15.3     5.508    4.437          13.005       14.994       641.96   \n",
       "IL       12.8     4.608    4.352          12.032       12.288       803.11   \n",
       "IN       14.5     3.625    4.205          13.775       13.775       710.46   \n",
       "IA       15.7     2.669    3.925          15.229       13.659       649.06   \n",
       "KS       17.8     4.806    4.272          13.706       15.130       780.45   \n",
       "KY       21.4     4.066    4.922          16.692       16.264       872.51   \n",
       "LA       20.5     7.175    6.765          14.965       20.090      1281.55   \n",
       "ME       15.1     5.738    4.530          13.137       12.684       661.88   \n",
       "MD       12.5     4.250    4.000           8.875       12.375      1048.78   \n",
       "MA        8.2     1.886    2.870           7.134        6.560      1011.14   \n",
       "MI       14.1     3.384    3.948          13.395       10.857      1110.61   \n",
       "MN        9.6     2.208    2.784           8.448        8.448       777.18   \n",
       "MS       17.6     2.640    5.456           1.760       17.600       896.07   \n",
       "MO       16.1     6.923    5.474          14.812       13.524       790.32   \n",
       "MT       21.4     8.346    9.416          17.976       18.190       816.21   \n",
       "NE       14.9     1.937    5.215          13.857       13.410       732.28   \n",
       "NV       14.7     5.439    4.704          13.965       14.553      1029.87   \n",
       "NH       11.6     4.060    3.480          10.092        9.628       746.54   \n",
       "NJ       11.2     1.792    3.136           9.632        8.736      1301.52   \n",
       "NM       18.4     3.496    4.968          12.328       18.032       869.85   \n",
       "NY       12.3     3.936    3.567          10.824        9.840      1234.31   \n",
       "NC       16.8     6.552    5.208          15.792       13.608       708.24   \n",
       "ND       23.9     5.497   10.038          23.661       20.554       688.75   \n",
       "OH       14.1     3.948    4.794          13.959       11.562       697.73   \n",
       "OK       19.9     6.368    5.771          18.308       18.706       881.51   \n",
       "OR       12.8     4.224    3.328           8.576       11.520       804.71   \n",
       "PA       18.2     9.100    5.642          17.472       16.016       905.99   \n",
       "RI       11.1     3.774    4.218          10.212        8.769      1148.99   \n",
       "SC       23.9     9.082    9.799          22.944       19.359       858.97   \n",
       "SD       19.4     6.014    6.402          19.012       16.684       669.31   \n",
       "TN       19.5     4.095    5.655          15.990       15.795       767.91   \n",
       "TX       19.4     7.760    7.372          17.654       16.878      1004.75   \n",
       "UT       11.3     4.859    1.808           9.944       10.848       809.38   \n",
       "VT       13.6     4.080    4.080          13.056       12.920       716.20   \n",
       "VA       12.7     2.413    3.429          11.049       11.176       768.95   \n",
       "WA       10.6     4.452    3.498           8.692        9.116       890.03   \n",
       "WV       23.8     8.092    6.664          23.086       20.706       992.61   \n",
       "WI       13.8     4.968    4.554           5.382       11.592       670.31   \n",
       "WY       17.4     7.308    5.568          14.094       15.660       791.14   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  \n",
       "AK          133.93  \n",
       "AZ          110.35  \n",
       "AR          142.39  \n",
       "CA          165.63  \n",
       "CO          139.91  \n",
       "CT          167.02  \n",
       "DE          151.48  \n",
       "DC          136.05  \n",
       "FL          144.18  \n",
       "GA          142.80  \n",
       "HI          120.92  \n",
       "ID           82.75  \n",
       "IL          139.15  \n",
       "IN          108.92  \n",
       "IA          114.47  \n",
       "KS          133.80  \n",
       "KY          137.13  \n",
       "LA          194.78  \n",
       "ME           96.57  \n",
       "MD          192.70  \n",
       "MA          135.63  \n",
       "MI          152.26  \n",
       "MN          133.35  \n",
       "MS          155.77  \n",
       "MO          144.45  \n",
       "MT           85.15  \n",
       "NE          114.82  \n",
       "NV          138.71  \n",
       "NH          120.21  \n",
       "NJ          159.85  \n",
       "NM          120.75  \n",
       "NY          150.01  \n",
       "NC          127.82  \n",
       "ND          109.72  \n",
       "OH          133.52  \n",
       "OK          178.86  \n",
       "OR          104.61  \n",
       "PA          153.86  \n",
       "RI          148.58  \n",
       "SC          116.29  \n",
       "SD           96.87  \n",
       "TN          155.57  \n",
       "TX          156.83  \n",
       "UT          109.48  \n",
       "VT          109.61  \n",
       "VA          153.72  \n",
       "WA          111.62  \n",
       "WV          152.56  \n",
       "WI          106.62  \n",
       "WY          122.04  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_17066/1110569478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2788\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2791\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Dense(units=3, input_dim=6, activation='relu'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction for ALABAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "AL       18.8     7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AL'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'AL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 21:21:31.888549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x=AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.68911695, -0.20726961, -0.15316689],\n",
       "        [-0.18045348, -0.0769875 ,  0.02181721],\n",
       "        [-0.38412485, -0.30931747,  0.20615518],\n",
       "        [ 0.61889243,  0.0939002 ,  0.5327381 ],\n",
       "        [-0.3902777 ,  0.5069946 ,  0.58469355],\n",
       "        [ 0.56200624, -0.254192  ,  0.35636914]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.05202603],\n",
       "        [-0.5525506 ],\n",
       "        [ 0.89845526]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for All USA States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - [ ] Add the predicitions as a new column in `dfsel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsel = df[['total']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsel['pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred\n",
       "abbrev             \n",
       "AL       18.8   1.0\n",
       "AK       18.1   1.0\n",
       "AZ       18.6   1.0\n",
       "AR       22.4   1.0\n",
       "CA       12.0   1.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - [ ] Why are these predictions so far away from reality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Mathematical Equation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In other words: calculate the `best numbers` for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Dense(units=3, input_dim=6, activation='relu'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: -4345.6611 - accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -4565.8066 - accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -4783.8760 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "1/6 [====>.........................] - ETA: 0s - loss: -4109.2866 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 21:21:45.758395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: -5008.6812 - accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -5232.2329 - accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -5458.9292 - accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -5688.2163 - accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -5909.4727 - accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -6130.7920 - accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: -6347.0806 - accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -6562.4575 - accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -6781.1240 - accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -7001.3892 - accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -7225.6123 - accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -7434.7173 - accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -7647.6621 - accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -7862.8164 - accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -8080.8286 - accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -8299.8145 - accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -8520.3047 - accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -8740.4619 - accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -8967.5459 - accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -9188.1729 - accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -9411.2432 - accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -9628.0332 - accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -9852.4453 - accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -10081.5332 - accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -10308.5742 - accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -10543.6074 - accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -10774.5068 - accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -11010.3945 - accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -11243.2773 - accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -11468.7998 - accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -11697.4365 - accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -11925.1484 - accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -12170.3389 - accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -12401.3555 - accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -12626.7812 - accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -12857.7588 - accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -13094.8799 - accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -13336.0127 - accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -13586.0225 - accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -13824.1152 - accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -14061.7803 - accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -14294.9365 - accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -14535.5479 - accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -14784.2900 - accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -15031.9873 - accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -15278.2959 - accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -15537.7227 - accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -15780.7246 - accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -16033.8770 - accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -16283.7803 - accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -16538.7051 - accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -16790.5781 - accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -17045.2070 - accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -17292.5332 - accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -17550.3281 - accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -17819.6582 - accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -18087.3906 - accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: -18359.9707 - accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -18629.8320 - accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -18898.0449 - accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -19167.7012 - accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -19436.8906 - accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -19716.0117 - accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -19993.0801 - accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -20272.4434 - accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -20553.8359 - accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -20836.4590 - accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -21118.9102 - accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -21400.4453 - accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -21687.1719 - accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -21976.1738 - accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -22270.6504 - accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -22549.8945 - accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -22844.5645 - accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -23137.4863 - accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -23416.9980 - accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -23698.7930 - accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -23986.7578 - accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: -24273.8027 - accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -24564.2734 - accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -24859.6973 - accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -25155.4199 - accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -25458.7402 - accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -25760.1094 - accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -26069.8008 - accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -26376.8926 - accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -26685.8867 - accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -27003.5117 - accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -27327.7207 - accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -27636.2852 - accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -27943.5859 - accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -28255.0898 - accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -28577.1680 - accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -28888.5371 - accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -29202.8906 - accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 13ms/step - loss: -29524.0723 - accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -29856.0215 - accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -30179.4961 - accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -30519.5234 - accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -30863.0918 - accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -31200.9727 - accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -31544.4492 - accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -31879.5020 - accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -32216.5449 - accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -32551.0020 - accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -32906.8438 - accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -33248.0938 - accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -33605.8906 - accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -33976.8633 - accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -34330.0938 - accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -34682.3750 - accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -35028.5039 - accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -35370.1641 - accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -35723.0820 - accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -36091.3164 - accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -36458.3047 - accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -36833.8516 - accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -37195.2969 - accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -37563.9102 - accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -37930.6953 - accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -38301.6055 - accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -38673.7422 - accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -39044.4297 - accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -39425.8477 - accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -39819.4531 - accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -40203.1055 - accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -40605.6406 - accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -40998.6602 - accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -41399.9414 - accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -41792.3477 - accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -42197.2188 - accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -42595.0117 - accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -43001.5742 - accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -43396.6797 - accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -43812.1680 - accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -44205.5156 - accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -44608.6406 - accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -45013.5391 - accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -45423.9180 - accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: -45854.9727 - accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -46282.3203 - accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -46706.6016 - accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -47140.5000 - accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: -47562.1250 - accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -48002.3555 - accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -48449.1094 - accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: -48889.4375 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2836ee040>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality **After `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_after_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred  pred_after_fit\n",
       "abbrev                             \n",
       "AL       18.8   1.0             1.0\n",
       "AK       18.1   1.0             1.0\n",
       "AZ       18.6   1.0             1.0\n",
       "AR       22.4   1.0             1.0\n",
       "CA       12.0   1.0             1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel['pred_after_fit'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`\n",
    "\n",
    "> - Have they changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.68911695, -0.6048538 ,  0.8565269 ],\n",
       "        [-0.18045348, -0.47824922,  1.0343088 ],\n",
       "        [-0.38412485, -0.705269  ,  1.2182956 ],\n",
       "        [ 0.61889243, -0.30547217,  1.5541798 ],\n",
       "        [-0.3902777 ,  0.0894011 ,  1.6284192 ],\n",
       "        [ 0.56200624, -0.6635271 ,  1.3988057 ]], dtype=float32),\n",
       " array([ 0.       , -0.4140838,  1.0453943], dtype=float32),\n",
       " array([[ 0.05202603],\n",
       "        [-0.2641793 ],\n",
       "        [ 1.9921898 ]], dtype=float32),\n",
       " array([0.8904457], dtype=float32)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - They are synonyms:\n",
    "> - Cost | Error | Loss\n",
    "> - https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `binary_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sparse_categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Dense(units=3, input_dim=6, activation='relu'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 15.2897 - accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2882 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 21:25:45.169112: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2867 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2852 - accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2837 - accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2822 - accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2807 - accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2792 - accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2777 - accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2762 - accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2747 - accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2732 - accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2717 - accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2702 - accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 15.2687 - accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2672 - accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2657 - accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2642 - accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2627 - accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2612 - accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2597 - accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2582 - accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2568 - accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2553 - accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2538 - accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2523 - accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2508 - accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2493 - accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2478 - accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2464 - accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2449 - accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2434 - accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2419 - accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2404 - accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2390 - accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2375 - accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.2360 - accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2345 - accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2331 - accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2316 - accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.2301 - accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2287 - accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2272 - accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2257 - accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2243 - accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2228 - accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2214 - accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2199 - accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2185 - accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2170 - accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2156 - accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2141 - accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2127 - accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2112 - accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2098 - accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.2084 - accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.2069 - accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2055 - accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2041 - accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2026 - accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.2012 - accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.1998 - accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1984 - accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1969 - accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1955 - accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1941 - accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1927 - accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1913 - accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1899 - accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1885 - accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1871 - accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1857 - accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1843 - accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1829 - accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1815 - accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1801 - accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1787 - accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1773 - accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1760 - accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1746 - accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1732 - accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1718 - accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1705 - accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1691 - accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1677 - accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1664 - accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1650 - accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1637 - accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1623 - accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1610 - accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.1596 - accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1583 - accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1570 - accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1556 - accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1543 - accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1530 - accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1517 - accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1503 - accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1490 - accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1477 - accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1464 - accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1451 - accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1438 - accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1425 - accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1412 - accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1399 - accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1386 - accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1373 - accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1360 - accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1348 - accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1335 - accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1322 - accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1310 - accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1297 - accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1284 - accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1272 - accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1259 - accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1247 - accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 15.1234 - accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1222 - accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1209 - accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1197 - accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1185 - accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1172 - accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1160 - accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1148 - accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1136 - accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1124 - accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1112 - accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1100 - accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1088 - accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1076 - accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.1064 - accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1052 - accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.1040 - accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1028 - accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1016 - accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.1004 - accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.0993 - accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 15.0981 - accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.0969 - accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.0958 - accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.0946 - accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.0935 - accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.0923 - accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 15.0912 - accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 15.0900 - accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.0889 - accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 15.0878 - accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 15.0866 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28066f460>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `mean_squared_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=206\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=206\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the `loss` accordingly to your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - [ ] Why is the model not improving as it iterates (**deep**ly **learn**s)?\n",
    "> - [ ] How can we solve this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=29\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=29\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=182\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=182\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configure `linear` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Dense(units=3, input_dim=6, activation='relu'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 732.7435 - accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 719.9960 - accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 707.3479 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 694.9557 - accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 749.3766 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 21:32:52.489666: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 682.8554 - accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 670.7330 - accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 658.7941 - accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 647.0215 - accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 635.7987 - accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 624.4465 - accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 613.5075 - accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 602.7794 - accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 592.2431 - accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 581.8562 - accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 571.3848 - accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 560.9492 - accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 550.9605 - accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 541.0477 - accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 531.3379 - accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 521.6375 - accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 512.0844 - accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 502.6803 - accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 493.4782 - accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 484.5482 - accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 475.9038 - accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 467.4598 - accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 458.9066 - accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 450.5698 - accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 442.2745 - accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 434.3713 - accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 426.3166 - accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 418.2729 - accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 410.4093 - accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 402.5968 - accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 394.9252 - accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 387.3091 - accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 379.8528 - accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 372.3565 - accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 364.7920 - accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 357.3686 - accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 349.8271 - accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 342.3583 - accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 334.5413 - accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 326.8759 - accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 319.1783 - accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 311.4337 - accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 303.5975 - accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 295.6296 - accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 287.7404 - accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 279.8061 - accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 271.5923 - accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 263.2490 - accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 254.7952 - accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 246.0598 - accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 237.1972 - accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 228.0999 - accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 218.5687 - accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 209.0202 - accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 199.1445 - accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 189.3016 - accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 178.8747 - accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 168.3235 - accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 157.3393 - accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 146.1990 - accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 134.6848 - accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 122.9343 - accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 110.8759 - accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 98.4284 - accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 86.0250 - accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 72.9503 - accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 59.6248 - accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 46.2740 - accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 32.4187 - accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 18.6751 - accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.2417 - accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.8639 - accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.9291 - accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.3999 - accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.1832 - accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1428 - accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0167 - accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0915 - accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1793 - accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.0650 - accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 3.0355 - accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.9490 - accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9852 - accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9099 - accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.9411 - accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.1785 - accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0455 - accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2.9040 - accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.9163 - accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.0893 - accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6916 - accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8300 - accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8547 - accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8514 - accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.8705 - accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.8556 - accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7322 - accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.9809 - accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8825 - accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8965 - accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.8693 - accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7456 - accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5860 - accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.5660 - accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5766 - accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.6064 - accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.5829 - accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.5688 - accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5048 - accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4713 - accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5044 - accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.5311 - accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4415 - accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.4102 - accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6408 - accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5463 - accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.4286 - accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7305 - accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3045 - accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4819 - accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3029 - accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2829 - accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.6628 - accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3994 - accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4698 - accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2292 - accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2578 - accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1926 - accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.2776 - accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.1876 - accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3801 - accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.2647 - accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.8700 - accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3980 - accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.3162 - accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4555 - accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.5694 - accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.2308 - accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0816 - accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0830 - accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.0435 - accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0872 - accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.1556 - accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.0360 - accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0566 - accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0707 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2845fb2b0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the `weights` (numbers) on the Mathematical Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2842ca0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 21:33:01.600059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsel = df[['total']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_initial</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.660452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>18.802872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.393461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>19.257086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>16.243856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_initial\n",
       "abbrev                     \n",
       "AL       18.8     18.660452\n",
       "AK       18.1     18.802872\n",
       "AZ       18.6     17.393461\n",
       "AR       22.4     19.257086\n",
       "CA       12.0     16.243856"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel['pred_initial'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `compile()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `fit()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality **After fit()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>initial_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  initial_pred\n",
       "abbrev                     \n",
       "AL       18.8           0.5\n",
       "AK       18.1           0.5\n",
       "AZ       18.6           0.5\n",
       "AR       22.4           0.5\n",
       "CA       12.0           0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel['pred_after_fit'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`\n",
    "\n",
    "> - Have they changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `relu` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tanh` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the predictions changing? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the `Weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/initializers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot (w_1) + alcohol \\cdot (w_2) \\ + ... + \\ ins\\_losses \\cdot (w_7) \\\\\n",
    "accidents = speeding \\cdot (0) + alcohol \\cdot (0) \\ + ... + \\ ins\\_losses \\cdot (0) \\\\\n",
    "accidents = speeding \\cdot (1) + alcohol \\cdot (1) \\ + ... + \\ ins\\_losses \\cdot (1) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to `glorot_uniform` (default)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/optimizers/#available-optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=324\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=324\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers comparison in GIF ‚Üí https://mlfromscratch.com/optimizers-explained/#adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla's Neural Network Models is composed of 48 models trainned in 70.000 hours of GPU ‚Üí https://tesla.com/ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Year with a 8 GPU Computer ‚Üí https://twitter.com/thirdrowtesla/status/1252723358342377472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gradient Descent `SGD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `compile()` the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 12:37:42.518624: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-07 12:37:42.522192: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-07 12:37:42.615884: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-07 12:37:42.821654: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `ADAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `RMSPROP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it take different times to get the best accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the end, what should be a feasible configuration of the Neural Network for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `kernel_initializer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `activation` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `optimizer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `loss` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network's importance to find **Non-Linear Patterns** in the Data\n",
    "\n",
    "> - The number of Neurons & Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87287&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Mathematical Formula\n",
    "- Weights / Kernel Initializer\n",
    "- Loss Function\n",
    "- Activation Function\n",
    "- Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What cannot you change arbitrarily of a Neural Network?\n",
    "\n",
    "- Input Neurons\n",
    "- Output Neurons\n",
    "- Loss Functions\n",
    "- Activation Functions"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jes√∫s L√≥pez @sotastica"
   }
  ],
  "interpreter": {
   "hash": "a2b8701b642343483c5f5e717bcb0768c6b951acf38d76a6fc8ea01492bda71d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
